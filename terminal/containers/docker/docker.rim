# terminal/containers/docker
' LeonardPauli/docs
	Created by Leonard Pauli, 23 mar 2018

// "A self-sufficient runtime for containers"

// TODO

related:
	- ./build-caching-issue
	- app/node/using-container

see container-orchestration.dictionary

installation:
	osx: // TODO
	ubuntu: // TODO
		// https://www.digitalocean.com/community/tutorials/webinar-series-getting-started-with-containers
		// https://docs.docker.com/install/linux/docker-ce/debian/#install-docker-ce
		- sudo apt-get remove docker docker-engine docker.io // uninstall possibly old versions
		- sudo apt-get update // update the apt package index
		- sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common gnupg2
		- "curl -fsSL https://download.docker.com/linux/$(. /etc/os-release; echo "$ID")/gpg | sudo apt-key add -" // add GPG key for official Docker repo
		- sudo apt-key fingerprint 0EBFCD88 // verify that you now have the key with the fingerprint 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88
		- sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/$(. /etc/os-release; echo "$ID") $(lsb_release -cs) stable" // add to apt (Advanced Package Tool)
		- sudo apt-get update // update apt package index (to include newly added repo)
		- apt-cache policy docker-ce // prioritize newly added repo
		- sudo apt-get install -y docker-ce // install docker
		check status: sudo systemctl status docker // systemctl used also for auto start on boot
		add user to docker group: sudo usermod -aG docker mydev // $USER
		relogin to apply: su - ${USER}
		test: docker


docker-machine // manages connections to docker
	install 
		// https://docs.docker.com/machine/install-machine/#installing-machine-directly
		- download, make executable, and copy in place: "curl -L https://github.com/docker/machine/releases/download/v0.12.2/docker-machine-`uname -s`-`uname -m` >/tmp/docker-machine && chmod +x /tmp/docker-machine && sudo cp /tmp/docker-machine /usr/local/bin/docker-machine"
		- test: "docker-machine -v"


commands:
	docker build -t [org-name/]image-name[:some-optional-tag] path/to/dir/containing/dockerfile
	docker build -t my-image . // build an image using ./Dockerfile, ./* as context, and name it my-name
	
	docker images // docker image ls, list images
	docker rmi my-image // docker image rm my-image, remove image
	docker image prune // docker rmi $(docker images -f "dangling=true" -q)

	docker run -t my-container -d -p 3000:80 my-image // start a new container, in detached mode (so it keeps running when closing terminal), using my-image, attaching container port 80 (EXPOSE 80) to host port 3000, naming it my-container
	docker logs -f --tail 10 // show last 10 log lines and counting, ctrl-c to stop
	// docker exec -it my-container sh // or bash, get terminal connection inside container, "exit" or ctrl-c to exit

	docker stop my-container
	docker kill my-container
	docker rm my-container

	docker run --rm -it alpine bash // create a temporary container that auto-removes when exiting
		// great for running / testing programs / scripts in relatively isolated environment
	
	docker pull some-remote-image // download image (including necessary intermediate layers)


base images:
	// always lock down with tags, or risk break in future
	- alpine // very light-weight setup with only the most necessary included, prefer if possible
	- alpine:3.7 // ~5MB, faster buildtime, use eg. apk add --update git
		// If you have native dependencies, you'll need extra tools
		// RUN apk add --no-cache make gcc g++ python
		// apk add --no-cache curl
	- ubuntu:16.04 // ~150MB, slower buildtime, use eg. apt-get update -q && apt-get install -yq git-core
	- node:9.11.1-alpine // https://github.com/nodejs/docker-node/blob/9023f588717d236a92d91a8483ff0582484c22d1/9/alpine/Dockerfile
		alt: mhart/alpine-node:10.0.0 // https://github.com/mhart/alpine-node/blob/master/Dockerfile
		// official (node:...) seems to have been based on mharts, + now have better support, though mharts seems more often updated?
		// -> probably best to use the official one
	- python:3.6-alpine3.7 // 87.5MB
	- nginx:1.13-alpine // 18MB, simple static web server (as default)
		server:
			image: nginx:1.13-alpine
			volumes: ["./public:/usr/share/nginx/html"]
			ports: ["80:80"]
	- ...

image.sha: // ensure validity for production
	# image=node:9.11-alpine; docker pull $image;
	# (security test/inspect the image)
	# sha=$(docker inspect --format='{{index .RepoDigests 0}}' $image)
	# imageWithSha=$(echo $sha | sed "s/.*@/$image@/")
	# node:9.11-alpine@sha256:5149aec8f508d48998e6230cdc8e6832cba192088b442c8ef7e23df3c6892cd3
	ARG imageWithSha
	FROM imageWithSha ...

Dockerfile // see https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#build-cache
	# comment
	// # FROM node:9.5.0-alpine@sha256:50ae5f22356c5a0b0c0ea76d27a453b0baf577c61633aee25cea93dcacec1630
	FROM org/image:tag@sha256:50ae5f... // add sha for security, prevents unexpected base image modifications
	RUN echo "hello" && echo "world" // each comman (RUN, FROM, etc) creates a new layer, so be mindful
	COPY host/rel-path host/other-path /container/abs/dest/ // dist ending with / -> put all inside (if source is folder, put its content inside (different from normal posix behavior))
		// if "COPY file1 file2 /destination/", "RUN mkdir -p /destination" first
	COPY host/rel-path /container/abs/dest // not ending with / -> replace (if source is file, or add contents inside if source is folder)
	WORKDIR /usr/src/app // like cd inside container, relevant for RUN, ENTRYPOINT, etc
	ENTRYPOINT ["command", "--flag", "argument", "etc"] // run by default when starting container
	EXPOSE 80 // allow port to be attached
	VOLUME /abs/container/path // declare possible volume, eg. for persistent db data, or for caches between re-builds, COPY/ADD commands won't affect directory after it's been declared as volume

	// avoid running server etc as root
	// https://stackoverflow.com/a/18949557/1054573
	// https://stackoverflow.com/questions/16573668/best-practices-when-running-node-js-with-port-80-ubuntu-linode
	ENV APPDIR /usr/local/app
	RUN addgroup -S mydev && adduser -S -G mydev mydev && \
		chown -R mydev:mydev "$APPDIR" && \
		chown -R mydev:mydev /mydev
	USER mydev
	// ENTRYPOINT ["start-server", ...

	// redirect port 80 (belov 1024 restricted by sudo) to port above 1024
	// RUN apk add iptables && iptables -t nat -I PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 3000
	// requires: "docker run --cap-add=NET_ADMIN" or cap_add: ["NET_ADMIN"] in docker-compose
	USER root
	RUN apk --no-cache add iptables
	' RUN iptables -t nat -I PREROUTING -p tcp --dport 80 -j REDIRECT --to-port $PORT
		requires "add_cap: NET_ADMIN" which docker annoyingly prevents during build..
		idea: wrapp entrypoint and prepend the command
			- catch22: command still requires sudo, but entrypoint + container should be run with limited user
		workaround: run after docker-compose up:
			myport=3000; myservice=my-service
			docker-compose exec --privileged -u root $myservice sh -c 'iptables -t nat -I PREROUTING -p tcp --dport 80 -j REDIRECT --to-port '"$myport"
	EXPOSE 80
	USER mydev // back to limited user


multi-stage-builds:
	Dockerfile:
		FROM alpine:3.7 as my-base
		// commands necessary in both dev and prod, eg. expose, some install, etc
		// ...


		// development

		FROM my-base as dev
		// add dev tools: ...
		VOLUME ... // have src as volume for hot reloading
		ENTRYPOINT ... // eg. use dev server


		// production

		FROM mhart/alpine-node:9.9 as dist-build
		COPY data /usr/src/app/
		CMD cd /usr/src/app && node build-to-dist

		FROM my-base as prod
		// extract only the product from gen step, keeping resulting image small
		COPY --from=dist-build /usr/src/app/dist /usr/src/app/dist
		ENTRYPOINT ... // eg. use prod server

	usage: // TODO: check; is .env used with docker-compose?
		- cli: env=dev; docker build --stage=$env -t my-app:$env .
		- docker-compose: // export env=dev && docker-compose build
			my-app:
				image: my-app:${env}
				build:
					context: .
					target: ${env}


network:
	docker-compose:
		services:
			my-app:
				networks:
					default:
						ipv4_address: 10.100.0.2

		networks:
			default:
				driver: bridge
				ipam:
					config:
						- subnet: 10.100.0.0/16
							gateway: 10.100.0.1



notes:
	.dockerignore
		put in context root
		like .gitignore, but relative to build context root + can only exist once
		use to exclude files/folders in contexts from being sent as context to docker
			eg. excluding node_modules can save a lot of time
			volumes can be excluded (they're attached after build, so doesn't have enything to do with build context anyhow)
	npm
		- npm install exclusively on Host or Container OS // if shared volume; installation (native modules) isn't same
	- lsof -n -i:PORT // list listening processes
	permissions:
		// see https://medium.com/@mccode/understanding-how-uid-and-gid-work-in-docker-containers-c37a01d01cf
		run -u=$UID:$UID
		root has $UID 0
		first user seems to have $UID 1000 // see /etc/passwd ?
		kernel (shared by all containers) handles permissions with UID, container maps UID to names
		for volumes:
			mkdir them with correct chmod/own before docker run and permissions will be kept, else they'll be created with root (it seems)
	performance:
		apart from docker NAT (and possibly "context switching" (?)), performance should be moslty same as native
			if run on linux
		- "https://stackoverflow.com/questions/21889053/what-is-the-runtime-performance-cost-of-a-docker-container"
			use --net=host instead of -p 80:80 to skip ~80% / 30ms roundtrip latency overhead of docker NAT (or shared bridge network between containers)
				though this looses the port whitelisting security + remapping ability
		- "https://blog.docker.com/2013/10/gathering-lxc-docker-containers-metrics/"
	network:
		disable: --net null
	memory:
		limit: --memory 1gb
	cpu:
		limit: --cpuset-cpus 0,2-3
	isolating GUI apps: // see http://somatorio.org/en/post/running-gui-apps-with-docker/
		// though on OSX, docker is run as VM, so performance affected?
	volumes in volumes are possible // eg.:
		// VOLUME /app
		// VOLUME /app/node_modules
		// volumes: ["./:/app", "./data/nm:/app/node_modules"]
		// # ./node_modules is ignored
